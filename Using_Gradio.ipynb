{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMzsyJg8qyKon089YRemApm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SarahPendhari/Distilbart-text-summarization-with-gradio/blob/main/Using_Gradio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio --quiet"
      ],
      "metadata": {
        "id": "drCir-lO6fXj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import dependencies"
      ],
      "metadata": {
        "id": "NmRzWvhd69jK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QJBnj850He7k"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import nltk\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the tokenizer and model\n"
      ],
      "metadata": {
        "id": "r4ddPJpn66PO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = \"sshleifer/distilbart-cnn-12-6\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SX1Nbsuo6Z_A",
        "outputId": "4914dc31-962b-4f1b-b778-0773cfad3f27"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define  the function to perform summarization"
      ],
      "metadata": {
        "id": "o7OwnFTR7Gne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_text(text):\n",
        "    # Split text into sentences\n",
        "    sentences = nltk.tokenize.sent_tokenize(text)\n",
        "\n",
        "    # Create chunks\n",
        "    chunks = []\n",
        "    chunk = \"\"\n",
        "    length = 0\n",
        "    for sentence in sentences:\n",
        "        combined_length = len(tokenizer.tokenize(sentence)) + length\n",
        "        if combined_length <= tokenizer.max_len_single_sentence:\n",
        "            chunk += sentence + \" \"\n",
        "            length = combined_length\n",
        "        else:\n",
        "            chunks.append(chunk.strip())\n",
        "            chunk = sentence + \" \"\n",
        "            length = len(tokenizer.tokenize(sentence))\n",
        "    chunks.append(chunk.strip())\n",
        "\n",
        "    # Generate summaries for each chunk\n",
        "    summaries = []\n",
        "    for chunk in chunks:\n",
        "        input_ids = tokenizer.encode(chunk, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
        "        summary_ids = model.generate(input_ids)\n",
        "        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "        summaries.append(summary)\n",
        "\n",
        "    # Combine summaries into a single string\n",
        "    summarized_text = \" \".join(summaries)\n",
        "    return summarized_text"
      ],
      "metadata": {
        "id": "at3URFf_7HZg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Gradio interface"
      ],
      "metadata": {
        "id": "n24d9Nmq7T8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iface = gr.Interface(fn=summarize_text,\n",
        "                      inputs=gr.Textbox(lines=20, label=\"Input Text\"),\n",
        "                      outputs=\"text\",\n",
        "                      title=\"Text Summarization\",\n",
        "                      description=\"Enter the text you want to summarize and click 'Summarize'.\")\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "QjkKdUNg7REU",
        "outputId": "48d399a8-9763-4be2-e2aa-5856d8faf626"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://716f31faa77ec3517e.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://716f31faa77ec3517e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GCY2ZkY97wje"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}